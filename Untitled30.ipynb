{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced1bb4d-68e2-48b7-881a-fe766ebfd907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (569, 30)\n",
      "Shape of y: (569,)\n",
      "Features: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "\n",
      "✅ Data loaded & standardized successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# ✅ TASK 1 – DATA LOADING & PREPROCESSING\n",
    "# ============================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "print(\"Features:\", data.feature_names)\n",
    "\n",
    "# Train-test split (70/30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(\"\\n✅ Data loaded & standardized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb047149-efce-49ba-9861-5a23d0a25f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ✅ TASK 2 – UTILITIES\n",
    "# ============================\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def sigmoid_derivative(A):\n",
    "    return A * (1 - A)\n",
    "\n",
    "def relu_derivative(Z):\n",
    "    return (Z > 0).astype(float)\n",
    "\n",
    "def compute_bce_loss(Y, Y_hat):\n",
    "    m = Y.shape[1]\n",
    "    eps = 1e-15\n",
    "    Y_hat = np.clip(Y_hat, eps, 1 - eps)\n",
    "    return -(1/m) * np.sum(Y*np.log(Y_hat) + (1-Y)*np.log(1-Y_hat))\n",
    "\n",
    "def compute_mse_loss(Y, Y_hat):\n",
    "    m = Y.shape[1]\n",
    "    return (1/m) * np.sum((Y_hat - Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74723b59-cb0e-4c25-bf45-9330d64860ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ✅ TASK 3 – UPDATED MYANN CLASSIFIER\n",
    "# ============================\n",
    "\n",
    "class MyANNClassifier:\n",
    "    def __init__(self, layer_dims, learning_rate=0.01, n_iterations=1000, loss='bce'):\n",
    "        self.layer_dims = layer_dims\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.loss = loss\n",
    "        self.parameters_ = {}\n",
    "        self.costs_ = []\n",
    "\n",
    "    def _initialize_parameters(self):\n",
    "        np.random.seed(1)\n",
    "        for l in range(1, len(self.layer_dims)):\n",
    "            self.parameters_['W' + str(l)] = np.random.randn(\n",
    "                self.layer_dims[l], self.layer_dims[l-1]\n",
    "            ) * 0.01\n",
    "            self.parameters_['b' + str(l)] = np.zeros((self.layer_dims[l], 1))\n",
    "\n",
    "    def _forward_propagation(self, X):\n",
    "        cache = []\n",
    "        A = X\n",
    "\n",
    "        for l in range(1, len(self.layer_dims)):\n",
    "            W = self.parameters_['W' + str(l)]\n",
    "            b = self.parameters_['b' + str(l)]\n",
    "            Z = np.dot(W, A) + b\n",
    "            \n",
    "            if l == len(self.layer_dims) - 1:\n",
    "                A = sigmoid(Z)  # Output layer\n",
    "            else:\n",
    "                A = relu(Z)     # Hidden layers\n",
    "            \n",
    "            cache.append((A, Z))\n",
    "\n",
    "        return A, cache\n",
    "\n",
    "    def _backward_propagation(self, Y, Y_hat, cache):\n",
    "        grads = {}\n",
    "        m = Y.shape[1]\n",
    "        L = len(self.layer_dims) - 1  # number of layers with weights\n",
    "\n",
    "        # ----- Output layer derivative (dA for last layer) -----\n",
    "        if self.loss == 'bce':\n",
    "            eps = 1e-15\n",
    "            Y_hat = np.clip(Y_hat, eps, 1-eps)\n",
    "            dA = -(np.divide(Y, Y_hat) - np.divide(1-Y, 1-Y_hat))\n",
    "        else:\n",
    "            dA = 2 * (Y_hat - Y)\n",
    "\n",
    "        # ----- Output layer -----\n",
    "        A_L, Z_L = cache[-1]\n",
    "        dZ = dA * sigmoid_derivative(A_L)\n",
    "\n",
    "        A_prev = cache[-2][0] if L > 1 else self.X_current  # If one-layer network, previous is input\n",
    "\n",
    "        grads[\"dW\" + str(L)] = (1/m) * np.dot(dZ, A_prev.T)\n",
    "        grads[\"db\" + str(L)] = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        # ----- Hidden layers -----\n",
    "        for l in reversed(range(1, L)):\n",
    "            A_l, Z_l = cache[l-1]\n",
    "            A_prev = cache[l-2][0] if l > 1 else self.X_current\n",
    "\n",
    "            W_next = self.parameters_['W' + str(l+1)]\n",
    "            dZ = np.dot(W_next.T, dZ) * relu_derivative(Z_l)\n",
    "\n",
    "            grads[\"dW\" + str(l)] = (1/m) * np.dot(dZ, A_prev.T)\n",
    "            grads[\"db\" + str(l)] = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def _update_parameters(self, grads):\n",
    "        L = len(self.layer_dims) - 1\n",
    "        for l in range(1, L + 1):\n",
    "            self.parameters_['W' + str(l)] -= self.learning_rate * grads['dW' + str(l)]\n",
    "            self.parameters_['b' + str(l)] -= self.learning_rate * grads['db' + str(l)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = X.T\n",
    "        y = y.reshape(1, -1)\n",
    "        self.X_current = X  # ✅ Needed for backward pass\n",
    "\n",
    "        self._initialize_parameters()\n",
    "\n",
    "        for i in range(self.n_iterations):\n",
    "            Y_hat, cache = self._forward_propagation(X)\n",
    "\n",
    "            if self.loss == 'bce':\n",
    "                cost = compute_bce_loss(y, Y_hat)\n",
    "            else:\n",
    "                cost = compute_mse_loss(y, Y_hat)\n",
    "\n",
    "            grads = self._backward_propagation(y, Y_hat, cache)\n",
    "            self._update_parameters(grads)\n",
    "\n",
    "            self.costs_.append(cost)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"Iteration {i} | Loss = {cost:.6f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.T\n",
    "        Y_hat, _ = self._forward_propagation(X)\n",
    "        predictions = (Y_hat > 0.5).astype(int)\n",
    "        return predictions.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d818256-1a03-4292-b3ca-9dc86488dd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 | Loss = 0.693108\n",
      "Iteration 1000 | Loss = 0.679339\n",
      "Iteration 2000 | Loss = 0.666914\n",
      "Iteration 3000 | Loss = 0.641780\n",
      "Iteration 4000 | Loss = 0.569008\n",
      "\n",
      "===== MODEL 1: BCE LOSS =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92        63\n",
      "           1       0.92      0.99      0.96       108\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.95      0.92      0.94       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n",
      "Iteration 0 | Loss = 0.249980\n",
      "Iteration 1000 | Loss = 0.246233\n",
      "Iteration 2000 | Loss = 0.243112\n",
      "Iteration 3000 | Loss = 0.240222\n",
      "Iteration 4000 | Loss = 0.236999\n",
      "\n",
      "===== MODEL 2: MSE LOSS =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        63\n",
      "           1       0.63      1.00      0.77       108\n",
      "\n",
      "    accuracy                           0.63       171\n",
      "   macro avg       0.32      0.50      0.39       171\n",
      "weighted avg       0.40      0.63      0.49       171\n",
      "\n",
      "Iteration 0 | Loss = 0.693150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yashv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yashv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000 | Loss = 0.680726\n",
      "Iteration 2000 | Loss = 0.673177\n",
      "Iteration 3000 | Loss = 0.668578\n",
      "Iteration 4000 | Loss = 0.665764\n",
      "\n",
      "===== MODEL 3: BCE (DEEPER) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        63\n",
      "           1       0.63      1.00      0.77       108\n",
      "\n",
      "    accuracy                           0.63       171\n",
      "   macro avg       0.32      0.50      0.39       171\n",
      "weighted avg       0.40      0.63      0.49       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yashv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yashv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# ✅ TASK 4 – TRAIN MODELS\n",
    "# ============================\n",
    "\n",
    "# Model 1 – BCE loss (1 hidden layer)\n",
    "model1 = MyANNClassifier(layer_dims=[30, 10, 1], learning_rate=0.001, n_iterations=5000, loss='bce')\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "pred1 = model1.predict(X_val_scaled)\n",
    "print(\"\\n===== MODEL 1: BCE LOSS =====\")\n",
    "print(classification_report(y_val, pred1))\n",
    "\n",
    "# Model 2 – MSE loss\n",
    "model2 = MyANNClassifier(layer_dims=[30, 10, 1], learning_rate=0.001, n_iterations=5000, loss='mse')\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "pred2 = model2.predict(X_val_scaled)\n",
    "print(\"\\n===== MODEL 2: MSE LOSS =====\")\n",
    "print(classification_report(y_val, pred2))\n",
    "\n",
    "# Model 3 – Deeper network (BCE)\n",
    "model3 = MyANNClassifier(layer_dims=[30, 10, 5, 1], learning_rate=0.001, n_iterations=5000, loss='bce')\n",
    "model3.fit(X_train_scaled, y_train)\n",
    "pred3 = model3.predict(X_val_scaled)\n",
    "print(\"\\n===== MODEL 3: BCE (DEEPER) =====\")\n",
    "print(classification_report(y_val, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33e60e-31dc-402d-8d7b-4cd1c9e967ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
